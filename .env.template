###############################################################################
# NOTE: With default settings Cognee only needs an OpenAI LLM_API_KEY to be set.
#       The rest of the settings don't have to be set.
#       Default relational database: SQLite
#       Default vector database   : LanceDB
#       Default graph database    : Kuzu
#
#       These default databases are all file-based, so no extra setup is needed
#       for local use. The data by default will be stored in your .venv
###############################################################################

################################################################################
#  üß† LLM Settings
################################################################################
# Currently we support BAML and Instructor(using litellm) for structured outputs
STRUCTURED_OUTPUT_FRAMEWORK="instructor"


################################################################################
#  üìÇ ROOT DIRECTORY FOR DATABASES
################################################################################
# Set up the Cognee system directory. Cognee will store system files and databases here.
# Useful for setting root directory inside docker and also to avoid storing the databases in .venv
# DATA_ROOT_DIRECTORY='/Users/<user>/Desktop/cognee/.cognee_data/'
# SYSTEM_ROOT_DIRECTORY='/Users/<user>/Desktop/cognee/.cognee_system/'

################################################################################
# üóÑÔ∏è Relational database settings
################################################################################

# DB_PROVIDER="sqlite"
# DB_NAME=cognee_db

# -- To switch to Postgres / PGVector, uncomment and fill these: -------------
DB_PROVIDER="postgres"
DB_NAME="cognee_db"
# To use Postgres with the Cognee backend in Docker compose use the following instead: DB_HOST=host.docker.internal
DB_HOST=host.docker.internal
DB_PORT=5432
DB_USERNAME=cognee
DB_PASSWORD=cognee

################################################################################
# üï∏Ô∏è Graph Database settings
################################################################################

# Default (local file-based)
#GRAPH_DATABASE_PROVIDER="kuzu"

# -- To switch to Remote Kuzu uncomment and fill these: -------------------------------------------------------------
#GRAPH_DATABASE_PROVIDER="kuzu"
#GRAPH_DATABASE_PROVIDER="kuzu-remote"
#GRAPH_DATABASE_URL="http://localhost:8000"
#GRAPH_DATABASE_USERNAME=XXX
#GRAPH_DATABASE_PASSWORD=YYY

# -- To switch to Neo4j uncomment and fill these: -------------------------------------------------------------------
GRAPH_DATABASE_PROVIDER="neo4j"
GRAPH_DATABASE_URL=bolt://neo4j:7687
GRAPH_DATABASE_NAME="neo4j"
GRAPH_DATABASE_USERNAME=neo4j
GRAPH_DATABASE_PASSWORD=pleaseletmein

################################################################################
#  üìê Vector Database settings
################################################################################

# Supported providers: pgvector | qdrant | weaviate | milvus | lancedb | chromadb
VECTOR_DB_PROVIDER="lancedb"
# Not needed if a cloud vector database is not used
# VECTOR_DB_URL=http://qdrant:6333
# VECTOR_DB_KEY=cognee



################################################################################
#  üîÑ  MIGRATION (RELATIONAL ‚Üí GRAPH) SETTINGS
################################################################################

MIGRATION_DB_PATH="/path/to/migration/directory"
MIGRATION_DB_NAME="migration_database.sqlite"
MIGRATION_DB_PROVIDER="sqlite"

# -- Postgres-specific migration params --------------------------------------
# MIGRATION_DB_USERNAME=cognee
# MIGRATION_DB_PASSWORD=cognee
# MIGRATION_DB_HOST="127.0.0.1"
# MIGRATION_DB_PORT=5432

################################################################################
# üîí Security Settings
################################################################################

# When set to false don't allow adding of local system files to Cognee. Should be set to False when Cognee is used as a backend.
ACCEPT_LOCAL_FILE_PATH=True

# When set to false don't allow HTTP requests to be sent from Cognee.
# This protects against Server Side Request Forgery when proper infrastructure is not in place.
ALLOW_HTTP_REQUESTS=True

# When set to False errors during data processing will be returned as info but not raised to allow handling of faulty documents
RAISE_INCREMENTAL_LOADING_ERRORS=True

# Set this variable to True to enforce usage of backend access control for Cognee
# Note: This is only currently supported by the following databases:
#       Relational: SQLite, Postgres
#       Vector: LanceDB
#       Graph: KuzuDB
#
# It enforces LanceDB and KuzuDB use and uses them to create databases per Cognee user + dataset
ENABLE_BACKEND_ACCESS_CONTROL=False

################################################################################
#  üõ†Ô∏è DEV Settings
################################################################################

ENV="local"

TOKENIZERS_PARALLELISM="false"

# LITELLM Logging Level. Set to quiet down logging
LITELLM_LOG=ERROR

# Set this environment variable to disable sending telemetry data
# TELEMETRY_DISABLED=1

# Default User Configuration
# DEFAULT_USER_EMAIL=""
# DEFAULT_USER_PASSWORD=""

# ------------------------------- END OF POSSIBLE SETTINGS -------------------------------


###############################################################################
# üß™  EXAMPLE OVERRIDES (commented out)
###############################################################################
# The blocks below show how to configure alternative providers.
# Uncomment + fill values to switch.

########## Azure OpenAI #######################################################
#LLM_MODEL="azure/gpt-5-mini"
#LLM_ENDPOINT="https://DNS.azure.com/openai/deployments/gpt-5-mini"
#LLM_API_KEY="<<TALK TO YOUR AZURE GUY"
#LLM_API_VERSION="2024-12-01-preview"

## llm api version might not be relevant
#LLM_MAX_TOKENS="16384"

#EMBEDDING_MODEL="azure/text-embedding-3-large"
#EMBEDDING_ENDPOINT="https://DNS.openai.azure.com/openai/deployments/text-embedding-3-large"
#EMBEDDING_API_KEY="<<TALK TO YOUR AZURE GUY>"
#EMBEDDING_API_VERSION="2024-12-01-preview"
#EMBEDDING_DIMENSIONS=3072
#EMBEDDING_MAX_TOKENS=8191

########## Local LLM via Ollama ###############################################

LLM_API_KEY="ollama"
LLM_MODEL=qwen3:4b-instruct-2507-q4_K_M
LLM_PROVIDER=ollama
LLM_ENDPOINT=http://ollama:11434/v1
EMBEDDING_PROVIDER=ollama
EMBEDDING_MODEL=dengcao/Qwen3-Embedding-4B:Q4_K_M
EMBEDDING_ENDPOINT=http://ollama:11434/api/embeddings
EMBEDDING_DIMENSIONS=2560
HUGGINGFACE_TOKENIZER=Salesforce/SFR-Embedding-Mistral

########## OpenRouter (also free) #########################################################

#LLM_API_KEY="<<go-get-one-yourself"
#LLM_PROVIDER="custom"
#LLM_MODEL="openrouter/google/gemini-2.0-flash-lite-preview-02-05:free"
#LLM_ENDPOINT="https://openrouter.ai/api/v1"

########## DeepInfra ##########################################################

#LLM_API_KEY="<<>>"
#LLM_PROVIDER="custom"
#LLM_MODEL="deepinfra/meta-llama/Meta-Llama-3-8B-Instruct"
#LLM_ENDPOINT="https://api.deepinfra.com/v1/openai"

#EMBEDDING_PROVIDER="openai"
#EMBEDDING_API_KEY="<<>>"
#EMBEDDING_MODEL="deepinfra/BAAI/bge-base-en-v1.5"
#EMBEDDING_ENDPOINT=""
#EMBEDDING_API_VERSION=""
#EMBEDDING_DIMENSIONS=3072
#EMBEDDING_MAX_TOKENS=8191


########## Release Test ###############################################

#LLM_API_KEY="..."

#OPENAI_API_KEY="..."

#MIGRATION_DB_PATH="~/Downloads/"
#MIGRATION_DB_NAME="Chinook_Sqlite.sqlite"
#MIGRATION_DB_PROVIDER="sqlite"

#GRAPH_DATABASE_URL="bolt://54.246.89.112:7687"
#GRAPH_DATABASE_USERNAME="neo4j"
#GRAPH_DATABASE_PASSWORD="pleaseletmein"
